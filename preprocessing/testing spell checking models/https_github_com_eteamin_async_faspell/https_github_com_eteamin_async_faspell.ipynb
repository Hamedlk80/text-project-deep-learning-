{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2Z72svl34vik",
        "KfQS-i45wkbN",
        "ra2yYyCVnJrw",
        "w7wUCcy5qDZV",
        "TcEkURF6nLzW",
        "jhgdW0iUrxnZ",
        "QV2CwIcsr8w5",
        "GzOlyEybOIOR"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#install hazm"
      ],
      "metadata": {
        "id": "2Z72svl34vik"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xo_KbxKWkJz_",
        "outputId": "f4cbcc72-44fe-48e5-c55b-940d181605a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hazm\n",
            "  Downloading hazm-0.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting fasttext-wheel<0.10.0,>=0.9.2 (from hazm)\n",
            "  Downloading fasttext_wheel-0.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting flashtext<3.0,>=2.7 (from hazm)\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gensim<5.0.0,>=4.3.1 (from hazm)\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from hazm) (3.9.1)\n",
            "Collecting numpy==1.24.3 (from hazm)\n",
            "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting python-crfsuite<0.10.0,>=0.9.9 (from hazm)\n",
            "  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /usr/local/lib/python3.11/dist-packages (from hazm) (1.6.1)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel<0.10.0,>=0.9.2->hazm)\n",
            "  Downloading pybind11-3.0.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (75.2.0)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim<5.0.0,>=4.3.1->hazm)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (7.3.0.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.67.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.6.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.1->hazm) (1.17.2)\n",
            "Downloading hazm-0.10.0-py3-none-any.whl (892 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m892.6/892.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasttext_wheel-0.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-3.0.0-py3-none-any.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: flashtext\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9300 sha256=cde837c3896c50bf05cda1c71492f69e1a7abc175eac0dcfb844daed058a57ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/20/47/f03dfa8a7239c54cbc44ff7389eefbf888d2c1873edaaec888\n",
            "Successfully built flashtext\n",
            "Installing collected packages: flashtext, python-crfsuite, pybind11, numpy, scipy, fasttext-wheel, gensim, hazm\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.1\n",
            "    Uninstalling scipy-1.16.1:\n",
            "      Successfully uninstalled scipy-1.16.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pywavelets 1.9.0 requires numpy<3,>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n",
            "jax 0.5.3 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n",
            "jaxlib 0.5.3 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "contourpy 1.3.3 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n",
            "pymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
            "arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fasttext-wheel-0.9.2 flashtext-2.7 gensim-4.3.3 hazm-0.10.0 numpy-1.24.3 pybind11-3.0.0 python-crfsuite-0.9.11 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "3834d882bc404c0597be269460cfae81"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install hazm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install parsivar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7JUHIptEpFy",
        "outputId": "1ac4a364-f6fb-4bc4-c229-a191e65ea9ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting parsivar\n",
            "  Downloading parsivar-0.2.3.1-py3-none-any.whl.metadata (242 bytes)\n",
            "Requirement already satisfied: nltk>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from parsivar) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.6.6->parsivar) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.6.6->parsivar) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.6.6->parsivar) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.6.6->parsivar) (4.67.1)\n",
            "Downloading parsivar-0.2.3.1-py3-none-any.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: parsivar\n",
            "Successfully installed parsivar-0.2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fLEHYlKE_8c",
        "outputId": "a326aafb-93b9-48cc-bf4d-558faca86576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.3.15.tar.gz (50.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (4.14.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (1.24.3)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.15-cp311-cp311-linux_x86_64.whl size=4397851 sha256=5b80aaa38b784c952f8be7ada8b1eb2d9b014e20cf0e929ff2a2675343be06b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/62/22/63039c8c4c8da7ff68e81b8357e64c199faff9df9a2b5e5e3b\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#imports"
      ],
      "metadata": {
        "id": "KfQS-i45wkbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hazm import Normalizer, word_tokenize\n",
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "2TASL2DikkgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from parsivar import Normalizer, SpellCheck"
      ],
      "metadata": {
        "id": "I03RcIlJjlFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from huggingface_hub import login\n",
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama\n",
        "import time\n",
        "import csv"
      ],
      "metadata": {
        "id": "JNMgdx-FDi7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Texts"
      ],
      "metadata": {
        "id": "ra2yYyCVnJrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Raw Farsi sentences (you can add your 20 samples here)\n",
        "texts = [\n",
        "    \"مي خواهم كتاب را بخوانم\",\n",
        "    \"سلام دكتر. فشار خونم خيلي ًبالاست !\",\n",
        "    \"دارو را   روزي سه بر بخور\",\n",
        "    \"از ديروز سر درد دارم 不客气 و هيچ دارويي نخوردم\",\n",
        "    \"چك كردم ولي قند خون نرمال بود\",\n",
        "    \"سلام دکتر 😊 دارو رو روزی 3 بار @ صبح‌ها بخور، اوکی؟ ❤️ #ممنون\",\n",
        "]"
      ],
      "metadata": {
        "id": "oZxyjHLOlXa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_texts = [\n",
        "    \"برای درمان تب و بدن‌درد،  باید هر 6 ساعت یک عد قرص استامینووفن 500 مصرف کند و هر 12 ساعت یک کپسول آموکسی‌یلین 500 بعد از غذا مصرف شود.خانم کرمی\",\n",
        "    \"آقای صادقی به دلیل باید روزی یک عدد قرص آسیترومایسین 250 به مدت سه روز همراه صبحانه مصرف کند سینوسیت حاد و قطره ونیل‌افرین را هر 8 ساعت در هر سوراخ بینی بچکاند.\",\n",
        "    \"خانم عسگری به دلیل آلرسی فصلی باید روزی دو عدد قرص سیتریسین همراه غذا مصرف کند و شب‌ها  شربت دیفن‌هیدراین قبل از خواب یک قاشق میل نماید.\",\n",
        "    \"کودک هفت‌ساله‌ای که دچار عفونت گلو شده است باید هر 8 ساعت 5 شربت فالکسین مصرف کند سی‌سی و هر 6 ساعت یک قاشق شربت استامینوفن برای تب تجویزه شده است.\",\n",
        "    \"آقای حسام برای زفلاکس معده باید شب‌هاقرص واموتیدین 40 قبل از خواب  یک عدد و همراه ناهار یک قرص رانیتیدین مصرف کند.\",\n",
        "    \"جهت درمان سرماخوردگی، خانم آقاجانی باید روزی یه بار لوراتادین قرص پس از غذا مصرف کند و شب‌ها قبل از خواب یک قاشق شربت دیفندرامین نیز میل نماید.\",\n",
        "    \"خانم فرمند با تشخیص برونخیت باید روزی یک عدد قرص آزیترومایسین با معده حالی و هر 80 ساعت یک عدد استامینوفن 500 مصرف نماید قرص .\",\n",
        "    \"روزی دو باربرای درد مواصل، آقای تقوی باید قرص ایبوپروفن 40 را هر 8 ساعت بعد از غذا و نابروکسن 250 را  همراه یک لیوان آب میل کند.\",\n",
        "    \"کودک ده‌ساله‌ای که کم‌خونی دارد باید روزی یک قرص آن همراه صبحانه و شربت آسکوربیک اسید نیز روزی دو بار برای جذب بهتر .\",\n",
        "    \"خانم مرادی که دچار حساسیت پوستی است باید روزی یک عدد قرص لوراتادین صبح‌ها و شب‌ها پماد هیدروکورنیزون را روی نواحی آسیب‌ بالد.\",\n",
        "    \"برای درمان عفونت مجازی ادراری، آقای خلیلی باید هر 112 ساعت یک کپسول سفالسین 500 و روزی سه بار قرص مترونیداول همراه غذا .\",\n",
        "    \"خانم داوری که با اسال شدید و التهاب  باید روزی دو بار قرص لوپرامید و هر روز صبح یک عدد قرص دگزامتازون . مصرف مایات فراموش شود.\",\n",
        "    \"کودک سه‌ساله با گلودرد ویروسی باید هر 6 ساعت یک قاشق شربت استامینوفن و هر 12 ساعت یک قاشق شربت هیستامین بعد از غذا .\",\n",
        "    \"آقای رفیعی با آلرژی تنفسی باید روزی یک عدد قرص فکسوونادین با شکم خالی و شب‌ها قبل از خواب شربت دیفن‌هیدرامین .\",\n",
        "    \"خانم اجباری که دچار کمبود ویتامین C شده است باید شربت آسکوربیک سید را روزی دو بار بعد از غذا و قرص ژینک را همراه وعده شام مصرف کند.\",\n",
        "    \"برای بهبود خواب، آقای شایان باید هر شب قبل از خواب یک عدد قرص ظولپیدم 10 مصرف کند و درصورت اضطراب، صبح‌ها یک قرص الپرازولان با معده خالی میل نماید.\",\n",
        "    \"کودک هشت‌ساله با اورتیت میانی باید هر 8 ساعت 5 سی‌سی شربت سفیکسلیم و شب‌ها قبل از خواب یک قاشق شربت دیفن‌هیدرامین  شود.\",\n",
        "    \"خانم نظری برای رفلاکس باید صبح‌ها ناشتا یک عدد قرص امپرازول و شب‌ها بعد از شام یک قرص فاموتیدین .\",\n",
        "    \"خانم نادری با سردرد مرمن باید روزی هر 66 ساعت یک عدد قرص استامینوفن 5000 مصرف کند  در صورت شدت درد، پماد موضعی منتول روی شقیشقه‌ها.\",\n",
        "    \" برای درمان عفونت شدید، آقای پرویزی باید روزی یک عدد قرص آسیترومایسین و هر 12 ساعت یک عدد آمپول چنتامایسین تزریقی طبق دستور زشک بزند.\"\n",
        "  ]"
      ],
      "metadata": {
        "id": "dS1HZ8EDKjgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#cleaning"
      ],
      "metadata": {
        "id": "w7wUCcy5qDZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_symbols_and_emojis(text):\n",
        "\n",
        "    # Define allowed punctuation: Persian and some general\n",
        "    allowed_punct = \"،.؟؛:!\"\n",
        "\n",
        "    # Build regex pattern:\n",
        "    # Pattern to match any character NOT in:\n",
        "    # - Persian Unicode range \\u0600-\\u06FF\n",
        "    # - English letters a-zA-Z\n",
        "    # - Digits 0-9 and Persian digits \\u06F0-\\u06F9\n",
        "    # - Half-space \\u200c\n",
        "    # - Whitespace \\s\n",
        "    # - Allowed punctuation\n",
        "    pattern = fr\"[^a-zA-Z0-9\\u06F0-\\u06F9\\u0600-\\u06FF\\u200c\\s{re.escape(allowed_punct)}]\"\n",
        "\n",
        "    # Remove disallowed characters (emojis, symbols, etc.)\n",
        "    cleaned = re.sub(pattern, \"\", text)\n",
        "\n",
        "    return cleaned\n"
      ],
      "metadata": {
        "id": "7b6dt4riokLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalizing"
      ],
      "metadata": {
        "id": "TcEkURF6nLzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize hazm normalizer\n",
        "normalizer = Normalizer()\n",
        "\n",
        "def normalize_farsi_sentences(sentences):\n",
        "    \"\"\"\n",
        "    Normalize a list of Farsi sentences using hazm.\n",
        "    \"\"\"\n",
        "    normalized = []\n",
        "    for sentence in sentences:\n",
        "        cleaned = normalizer.normalize(sentence)\n",
        "        normalized.append(cleaned)\n",
        "    return normalized\n"
      ],
      "metadata": {
        "id": "iQyTPR62lYG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#applying cleaning and normalizing"
      ],
      "metadata": {
        "id": "jhgdW0iUrxnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean + Normalize pipeline\n",
        "cleaned_texts = [clean_symbols_and_emojis(t) for t in the_texts]\n",
        "normalized_texts = [normalizer.normalize(t) for t in cleaned_texts]\n",
        "\n",
        "# Show original, cleaned, and normalized\n",
        "for i, (orig, clean, norm) in enumerate(zip(the_texts, cleaned_texts, normalized_texts), 1):\n",
        "    print(f\"{i}. Original   : {orig}\")\n",
        "    print(f\"   Cleaned    : {clean}\")\n",
        "    print(f\"   Normalized : {norm}\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4H4NohPlbuJ",
        "outputId": "f44bb3ca-dad6-4673-d528-b852edc5fa0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Original   : برای درمان تب و بدن‌درد،  باید هر 6 ساعت یک عد قرص استامینووفن 500 مصرف کند و هر 12 ساعت یک کپسول آموکسی‌یلین 500 بعد از غذا مصرف شود.خانم کرمی\n",
            "   Cleaned    : برای درمان تب و بدن‌درد،  باید هر 6 ساعت یک عد قرص استامینووفن 500 مصرف کند و هر 12 ساعت یک کپسول آموکسی‌یلین 500 بعد از غذا مصرف شود.خانم کرمی\n",
            "   Normalized : برای درمان تب و بدن‌درد ، باید هر 6 ساعت یک عد قرص استامینووفن 500 مصرف کند و هر 12 ساعت یک کپسول آموکسی‌یلین 500 بعد از غذا مصرف شود . خانم کرمی\n",
            "--------------------------------------------------\n",
            "2. Original   : آقای صادقی به دلیل باید روزی یک عدد قرص آسیترومایسین 250 به مدت سه روز همراه صبحانه مصرف کند سینوسیت حاد و قطره ونیل‌افرین را هر 8 ساعت در هر سوراخ بینی بچکاند.\n",
            "   Cleaned    : آقای صادقی به دلیل باید روزی یک عدد قرص آسیترومایسین 250 به مدت سه روز همراه صبحانه مصرف کند سینوسیت حاد و قطره ونیل‌افرین را هر 8 ساعت در هر سوراخ بینی بچکاند.\n",
            "   Normalized : آقای صادقی به دلیل باید روزی یک عدد قرص آسیترومایسین 250 به مدت سه روز همراه صبحانه مصرف کند سینوسیت حاد و قطره ونیل‌افرین را هر 8 ساعت در هر سوراخ بینی بچکاند .\n",
            "--------------------------------------------------\n",
            "3. Original   : خانم عسگری به دلیل آلرسی فصلی باید روزی دو عدد قرص سیتریسین همراه غذا مصرف کند و شب‌ها  شربت دیفن‌هیدراین قبل از خواب یک قاشق میل نماید.\n",
            "   Cleaned    : خانم عسگری به دلیل آلرسی فصلی باید روزی دو عدد قرص سیتریسین همراه غذا مصرف کند و شب‌ها  شربت دیفن‌هیدراین قبل از خواب یک قاشق میل نماید.\n",
            "   Normalized : خانم عسگری به دلیل آلرسی فصلی باید روزی دو عدد قرص سیتریسین همراه غذا مصرف کند و شب‌ها شربت دیفن‌هیدراین قبل از خواب یک قاشق میل نماید .\n",
            "--------------------------------------------------\n",
            "4. Original   : کودک هفت‌ساله‌ای که دچار عفونت گلو شده است باید هر 8 ساعت 5 شربت فالکسین مصرف کند سی‌سی و هر 6 ساعت یک قاشق شربت استامینوفن برای تب تجویزه شده است.\n",
            "   Cleaned    : کودک هفت‌ساله‌ای که دچار عفونت گلو شده است باید هر 8 ساعت 5 شربت فالکسین مصرف کند سی‌سی و هر 6 ساعت یک قاشق شربت استامینوفن برای تب تجویزه شده است.\n",
            "   Normalized : کودک هفت‌ساله‌ای که دچار عفونت گلو‌شده‌است باید هر 8 ساعت 5 شربت فالکسین مصرف کند سی‌سی و هر 6 ساعت یک قاشق شربت استامینوفن برای تب تجویزه‌شده‌است .\n",
            "--------------------------------------------------\n",
            "5. Original   : آقای حسام برای زفلاکس معده باید شب‌هاقرص واموتیدین 40 قبل از خواب  یک عدد و همراه ناهار یک قرص رانیتیدین مصرف کند.\n",
            "   Cleaned    : آقای حسام برای زفلاکس معده باید شب‌هاقرص واموتیدین 40 قبل از خواب  یک عدد و همراه ناهار یک قرص رانیتیدین مصرف کند.\n",
            "   Normalized : آقای حسام برای زفلاکس معده باید شب‌هاقرص واموتیدین 40 قبل از خواب یک عدد و همراه ناهار یک قرص رانیتیدین مصرف کند .\n",
            "--------------------------------------------------\n",
            "6. Original   : جهت درمان سرماخوردگی، خانم آقاجانی باید روزی یه بار لوراتادین قرص پس از غذا مصرف کند و شب‌ها قبل از خواب یک قاشق شربت دیفندرامین نیز میل نماید.\n",
            "   Cleaned    : جهت درمان سرماخوردگی، خانم آقاجانی باید روزی یه بار لوراتادین قرص پس از غذا مصرف کند و شب‌ها قبل از خواب یک قاشق شربت دیفندرامین نیز میل نماید.\n",
            "   Normalized : جهت درمان سرماخوردگی ، خانم آقاجانی باید روزی یه بار لوراتادین قرص پس از غذا مصرف کند و شب‌ها قبل از خواب یک قاشق شربت دیفندرامین نیز میل نماید .\n",
            "--------------------------------------------------\n",
            "7. Original   : خانم فرمند با تشخیص برونخیت باید روزی یک عدد قرص آزیترومایسین با معده حالی و هر 80 ساعت یک عدد استامینوفن 500 مصرف نماید قرص .\n",
            "   Cleaned    : خانم فرمند با تشخیص برونخیت باید روزی یک عدد قرص آزیترومایسین با معده حالی و هر 80 ساعت یک عدد استامینوفن 500 مصرف نماید قرص .\n",
            "   Normalized : خانم فرمند با تشخیص برونخیت باید روزی یک عدد قرص آزیترومایسین با معده حالی و هر 80 ساعت یک عدد استامینوفن 500 مصرف نماید قرص .\n",
            "--------------------------------------------------\n",
            "8. Original   : روزی دو باربرای درد مواصل، آقای تقوی باید قرص ایبوپروفن 40 را هر 8 ساعت بعد از غذا و نابروکسن 250 را  همراه یک لیوان آب میل کند.\n",
            "   Cleaned    : روزی دو باربرای درد مواصل، آقای تقوی باید قرص ایبوپروفن 40 را هر 8 ساعت بعد از غذا و نابروکسن 250 را  همراه یک لیوان آب میل کند.\n",
            "   Normalized : روزی دو باربرای درد مواصل ، آقای تقوی باید قرص ایبوپروفن 40 را هر 8 ساعت بعد از غذا و نابروکسن 250 را همراه یک لیوان آب میل کند .\n",
            "--------------------------------------------------\n",
            "9. Original   : کودک ده‌ساله‌ای که کم‌خونی دارد باید روزی یک قرص آن همراه صبحانه و شربت آسکوربیک اسید نیز روزی دو بار برای جذب بهتر .\n",
            "   Cleaned    : کودک ده‌ساله‌ای که کم‌خونی دارد باید روزی یک قرص آن همراه صبحانه و شربت آسکوربیک اسید نیز روزی دو بار برای جذب بهتر .\n",
            "   Normalized : کودک ده‌ساله‌ای که کم‌خونی دارد باید روزی یک قرص آن همراه صبحانه و شربت آسکوربیک اسید نیز روزی دو بار برای جذب بهتر .\n",
            "--------------------------------------------------\n",
            "10. Original   : خانم مرادی که دچار حساسیت پوستی است باید روزی یک عدد قرص لوراتادین صبح‌ها و شب‌ها پماد هیدروکورنیزون را روی نواحی آسیب‌ بالد.\n",
            "   Cleaned    : خانم مرادی که دچار حساسیت پوستی است باید روزی یک عدد قرص لوراتادین صبح‌ها و شب‌ها پماد هیدروکورنیزون را روی نواحی آسیب‌ بالد.\n",
            "   Normalized : خانم مرادی که دچار حساسیت پوستی است باید روزی یک عدد قرص لوراتادین صبح‌ها و شب‌ها پماد هیدروکورنیزون را روی نواحی آسیب‌ بالد .\n",
            "--------------------------------------------------\n",
            "11. Original   : برای درمان عفونت مجازی ادراری، آقای خلیلی باید هر 112 ساعت یک کپسول سفالسین 500 و روزی سه بار قرص مترونیداول همراه غذا .\n",
            "   Cleaned    : برای درمان عفونت مجازی ادراری، آقای خلیلی باید هر 112 ساعت یک کپسول سفالسین 500 و روزی سه بار قرص مترونیداول همراه غذا .\n",
            "   Normalized : برای درمان عفونت مجازی ادراری ، آقای خلیلی باید هر 112 ساعت یک کپسول سفالسین 500 و روزی سه بار قرص مترونیداول همراه غذا .\n",
            "--------------------------------------------------\n",
            "12. Original   : خانم داوری که با اسال شدید و التهاب  باید روزی دو بار قرص لوپرامید و هر روز صبح یک عدد قرص دگزامتازون . مصرف مایات فراموش شود.\n",
            "   Cleaned    : خانم داوری که با اسال شدید و التهاب  باید روزی دو بار قرص لوپرامید و هر روز صبح یک عدد قرص دگزامتازون . مصرف مایات فراموش شود.\n",
            "   Normalized : خانم داوری که با اسال شدید و التهاب باید روزی دو بار قرص لوپرامید و هر روز صبح یک عدد قرص دگزامتازون . مصرف مایات فراموش شود .\n",
            "--------------------------------------------------\n",
            "13. Original   : کودک سه‌ساله با گلودرد ویروسی باید هر 6 ساعت یک قاشق شربت استامینوفن و هر 12 ساعت یک قاشق شربت هیستامین بعد از غذا .\n",
            "   Cleaned    : کودک سه‌ساله با گلودرد ویروسی باید هر 6 ساعت یک قاشق شربت استامینوفن و هر 12 ساعت یک قاشق شربت هیستامین بعد از غذا .\n",
            "   Normalized : کودک سه‌ساله با گلودرد ویروسی باید هر 6 ساعت یک قاشق شربت استامینوفن و هر 12 ساعت یک قاشق شربت هیستامین بعد از غذا .\n",
            "--------------------------------------------------\n",
            "14. Original   : آقای رفیعی با آلرژی تنفسی باید روزی یک عدد قرص فکسوونادین با شکم خالی و شب‌ها قبل از خواب شربت دیفن‌هیدرامین .\n",
            "   Cleaned    : آقای رفیعی با آلرژی تنفسی باید روزی یک عدد قرص فکسوونادین با شکم خالی و شب‌ها قبل از خواب شربت دیفن‌هیدرامین .\n",
            "   Normalized : آقای رفیعی با آلرژی تنفسی باید روزی یک عدد قرص فکسوونادین با شکم خالی و شب‌ها قبل از خواب شربت دیفن‌هیدرامین .\n",
            "--------------------------------------------------\n",
            "15. Original   : خانم اجباری که دچار کمبود ویتامین C شده است باید شربت آسکوربیک سید را روزی دو بار بعد از غذا و قرص ژینک را همراه وعده شام مصرف کند.\n",
            "   Cleaned    : خانم اجباری که دچار کمبود ویتامین C شده است باید شربت آسکوربیک سید را روزی دو بار بعد از غذا و قرص ژینک را همراه وعده شام مصرف کند.\n",
            "   Normalized : خانم اجباری که دچار کمبود ویتامین C‌شده‌است باید شربت آسکوربیک سید را روزی دو بار بعد از غذا و قرص ژینک را همراه وعده شام مصرف کند .\n",
            "--------------------------------------------------\n",
            "16. Original   : برای بهبود خواب، آقای شایان باید هر شب قبل از خواب یک عدد قرص ظولپیدم 10 مصرف کند و درصورت اضطراب، صبح‌ها یک قرص الپرازولان با معده خالی میل نماید.\n",
            "   Cleaned    : برای بهبود خواب، آقای شایان باید هر شب قبل از خواب یک عدد قرص ظولپیدم 10 مصرف کند و درصورت اضطراب، صبح‌ها یک قرص الپرازولان با معده خالی میل نماید.\n",
            "   Normalized : برای بهبود خواب ، آقای شایان باید هر شب قبل از خواب یک عدد قرص ظولپیدم 10 مصرف کند و درصورت اضطراب ، صبح‌ها یک قرص الپرازولان با معده خالی میل نماید .\n",
            "--------------------------------------------------\n",
            "17. Original   : کودک هشت‌ساله با اورتیت میانی باید هر 8 ساعت 5 سی‌سی شربت سفیکسلیم و شب‌ها قبل از خواب یک قاشق شربت دیفن‌هیدرامین  شود.\n",
            "   Cleaned    : کودک هشت‌ساله با اورتیت میانی باید هر 8 ساعت 5 سی‌سی شربت سفیکسلیم و شب‌ها قبل از خواب یک قاشق شربت دیفن‌هیدرامین  شود.\n",
            "   Normalized : کودک هشت‌ساله با اورتیت میانی باید هر 8 ساعت 5 سی‌سی شربت سفیکسلیم و شب‌ها قبل از خواب یک قاشق شربت دیفن‌هیدرامین شود .\n",
            "--------------------------------------------------\n",
            "18. Original   : خانم نظری برای رفلاکس باید صبح‌ها ناشتا یک عدد قرص امپرازول و شب‌ها بعد از شام یک قرص فاموتیدین .\n",
            "   Cleaned    : خانم نظری برای رفلاکس باید صبح‌ها ناشتا یک عدد قرص امپرازول و شب‌ها بعد از شام یک قرص فاموتیدین .\n",
            "   Normalized : خانم نظری برای رفلاکس باید صبح‌ها ناشتا یک عدد قرص امپرازول و شب‌ها بعد از شام یک قرص فاموتیدین .\n",
            "--------------------------------------------------\n",
            "19. Original   : خانم نادری با سردرد مرمن باید روزی هر 66 ساعت یک عدد قرص استامینوفن 5000 مصرف کند  در صورت شدت درد، پماد موضعی منتول روی شقیشقه‌ها.\n",
            "   Cleaned    : خانم نادری با سردرد مرمن باید روزی هر 66 ساعت یک عدد قرص استامینوفن 5000 مصرف کند  در صورت شدت درد، پماد موضعی منتول روی شقیشقه‌ها.\n",
            "   Normalized : خانم نادری با سردرد مرمن باید روزی هر 66 ساعت یک عدد قرص استامینوفن 5000 مصرف کند در صورت شدت درد ، پماد موضعی منتول روی شقیشقه‌ها .\n",
            "--------------------------------------------------\n",
            "20. Original   :  برای درمان عفونت شدید، آقای پرویزی باید روزی یک عدد قرص آسیترومایسین و هر 12 ساعت یک عدد آمپول چنتامایسین تزریقی طبق دستور زشک بزند.\n",
            "   Cleaned    :  برای درمان عفونت شدید، آقای پرویزی باید روزی یک عدد قرص آسیترومایسین و هر 12 ساعت یک عدد آمپول چنتامایسین تزریقی طبق دستور زشک بزند.\n",
            "   Normalized : برای درمان عفونت شدید ، آقای پرویزی باید روزی یک عدد قرص آسیترومایسین و هر 12 ساعت یک عدد آمپول چنتامایسین تزریقی طبق دستور زشک بزند .\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#creat a csv"
      ],
      "metadata": {
        "id": "QV2CwIcsr8w5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"Original\": the_texts,\n",
        "    \"Cleaned\": cleaned_texts,\n",
        "    \"Normalized\": normalized_texts\n",
        "})\n",
        "df.to_csv(\"farsi_cleaned_normalized.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"✅ Exported to farsi_cleaned_normalized.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_CNEt8imlBa",
        "outputId": "adc874bb-1bfb-4a96-f9c2-6407769db4f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Exported to farsi_cleaned_normalized.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# loading and testing model"
      ],
      "metadata": {
        "id": "GzOlyEybOIOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aiofiles faspell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71IrLJ8XTrmJ",
        "outputId": "72b91da8-eae5-4a26-bab0-f2bb5c721979"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.11/dist-packages (24.1.0)\n",
            "Requirement already satisfied: faspell in /usr/local/lib/python3.11/dist-packages (0.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- تنظیمات سریع ---\n",
        "LEXICON_PATH = \"fa_words.txt\"  # اگر وجود نداشته باشد، به‌طور خودکار از hazm دانلود می‌شود\n",
        "HAZM_WORDS_URL = \"https://raw.githubusercontent.com/sobhe/hazm/master/hazm/data/words.dat\"\n",
        "\n",
        "IN_CSV  = \"farsi_cleaned_normalized.csv\"\n",
        "IN_COL  = \"Normalized\"\n",
        "OUT_CSV = \"farsi_async_faspell_corrected_on_normalized.csv\"\n",
        "OUT_COL = \"async_faspell_on_Normalized\"\n",
        "\n",
        "# --- اگر در Colab هستید، اول این را اجرا کنید:\n",
        "# !pip install -q aiofiles faspell\n",
        "\n",
        "import os\n",
        "import re\n",
        "import asyncio\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "\n",
        "# تلاش برای وارد کردن پکیج‌ها؛ پیام راهنما اگر نصب نشده باشد\n",
        "try:\n",
        "    from faspell.spell_checker import SpellChecker  # async_faspell\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\n",
        "        \"پکیج faspell نصب نیست. لطفاً اجرا کنید: pip install faspell aiofiles\"\n",
        "    ) from e\n",
        "\n",
        "import aiofiles\n",
        "\n",
        "# --- ابزار دانلود امن (بدون وابستگی به !wget) ---\n",
        "def ensure_lexicon(path: str, fallback_url: str) -> str:\n",
        "    \"\"\"\n",
        "    اگر فایل لغت‌نامه موجود نبود، از fallback_url دانلود می‌کند و در path ذخیره می‌کند.\n",
        "    در پایان مسیر فایل موجود را برمی‌گرداند.\n",
        "    \"\"\"\n",
        "    if os.path.isfile(path) and os.path.getsize(path) > 0:\n",
        "        return path\n",
        "    # دانلود hazm words.dat و ذخیره به عنوان fa_words.txt\n",
        "    try:\n",
        "        import urllib.request\n",
        "        print(f\"⬇️  در حال دانلود لغت‌نامه از {fallback_url} ...\")\n",
        "        with urllib.request.urlopen(fallback_url) as resp:\n",
        "            data = resp.read().decode(\"utf-8\")\n",
        "        # hazm/words.dat یک واژه در هر خط است؛ همان را ذخیره می‌کنیم\n",
        "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(data)\n",
        "        if os.path.getsize(path) == 0:\n",
        "            raise IOError(\"دانلود انجام شد ولی فایل خالی است.\")\n",
        "        print(f\"✅ لغت‌نامه در «{path}» ذخیره شد.\")\n",
        "        return path\n",
        "    except Exception as e:\n",
        "        raise FileNotFoundError(\n",
        "            f\"نتوانستم لغت‌نامه را پیدا/دانلود کنم. یا «{path}» را دستی بسازید، \"\n",
        "            f\"یا اتصال اینترنت را بررسی کنید. خطا: {e}\"\n",
        "        )\n",
        "\n",
        "# --- الگوهای کلمه فارسی و توکن‌سازی ساده ---\n",
        "PERSIAN_ARABIC_CHARS = r\"\\u0600-\\u06FF\\u0750-\\u077F\\u08A0-\\u08FF\"\n",
        "WORD_RE = re.compile(rf\"[{PERSIAN_ARABIC_CHARS}]+(?:[{PERSIAN_ARABIC_CHARS}‌\\-]+)*\")\n",
        "\n",
        "def is_persian_word(w: str) -> bool:\n",
        "    w = w.strip(\".,!?؛،:()[]{}«»\\\"'…\")\n",
        "    return bool(w) and bool(re.fullmatch(rf\"[{PERSIAN_ARABIC_CHARS}‌\\-]+\", w))\n",
        "\n",
        "def tokenize_sentence_keep_punct(s: str) -> List[str]:\n",
        "    # تقسیم خیلی ساده بر اساس فاصله؛ علائم حفظ می‌شوند\n",
        "    return s.split()\n",
        "\n",
        "def rebuild_sentence(tokens: List[str]) -> str:\n",
        "    txt = \" \".join(tokens)\n",
        "    # اصلاح فاصله‌ها پیرامون علائم رایج\n",
        "    txt = re.sub(r\"\\s+([،؛,.!?؟…])\", r\"\\1\", txt)\n",
        "    txt = re.sub(r\"«\\s+\", \"«\", txt)\n",
        "    txt = re.sub(r\"\\s+»\", \"»\", txt)\n",
        "    return txt\n",
        "\n",
        "import asyncio\n",
        "\n",
        "async def load_spellchecker(lexicon_path: str) -> \"SpellChecker\":\n",
        "    # مثل قبل، ولی ok\n",
        "    import aiofiles\n",
        "    from faspell.spell_checker import SpellChecker\n",
        "    async with aiofiles.open(lexicon_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        lex_text = await f.read()\n",
        "    return SpellChecker(lex_text)\n",
        "\n",
        "async def correct_token(sp, token: str) -> str:\n",
        "    core = token.strip(\".,!?؛،:()[]{}«»\\\"'…\")\n",
        "    if not core or not re.fullmatch(rf\"[{PERSIAN_ARABIC_CHARS}‌\\-]+\", core):\n",
        "        return token\n",
        "\n",
        "    # سازگار با هر دو پیاده‌سازی: اگر خروجی coroutine بود await کن، وگرنه مستقیم استفاده کن\n",
        "    res = sp.correct(core)\n",
        "    if asyncio.iscoroutine(res):\n",
        "        suggs = await res\n",
        "    else:\n",
        "        suggs = res  # sync list\n",
        "\n",
        "    if not suggs:\n",
        "        return token\n",
        "    best = suggs[0]\n",
        "    if best == core:\n",
        "        return token\n",
        "\n",
        "    prefix = token[:len(token) - len(token.lstrip(\"«({[\\\"'\"))]\n",
        "    suffix = token[len(token.rstrip(\".,!?؛،:)}]»\\\"'…\")):]\n",
        "    return f\"{prefix}{best}{suffix}\"\n",
        "\n",
        "async def correct_sentence(sp: SpellChecker, sentence: str) -> str:\n",
        "    tokens = tokenize_sentence_keep_punct(sentence)\n",
        "    tasks = [correct_token(sp, tk) for tk in tokens]\n",
        "    fixed_tokens = await asyncio.gather(*tasks)\n",
        "    return rebuild_sentence(fixed_tokens)\n",
        "\n",
        "async def process_csv(\n",
        "    lexicon_path: str,\n",
        "    in_csv: str,\n",
        "    in_col: str,\n",
        "    out_csv: str,\n",
        "    out_col: str,\n",
        "    batch_size: int = 256\n",
        "):\n",
        "    # 1) بارگذاری لغت‌نامه\n",
        "    sp = await load_spellchecker(lexicon_path)\n",
        "\n",
        "    # 2) خواندن CSV\n",
        "    df = pd.read_csv(in_csv)\n",
        "    if in_col not in df.columns:\n",
        "        raise KeyError(f\"ستون «{in_col}» در CSV پیدا نشد. ستون‌ها: {list(df.columns)}\")\n",
        "    texts = df[in_col].fillna(\"\").astype(str).tolist()\n",
        "\n",
        "    # 3) اجرای اصلاحات به‌صورت دسته‌ای\n",
        "    corrected = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        tasks = [correct_sentence(sp, t) for t in batch]\n",
        "        corrected.extend(await asyncio.gather(*tasks))\n",
        "\n",
        "    # 4) ذخیره خروجی\n",
        "    df[out_col] = corrected\n",
        "    df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"✅ Saved to {out_csv}\")\n",
        "\n",
        "# ---------- اجرای یک‌کلیکی ----------\n",
        "# 1) اطمینان از وجود لغت‌نامه (در صورت نبود، دانلود از hazm)\n",
        "lex_path = ensure_lexicon(LEXICON_PATH, HAZM_WORDS_URL)\n",
        "\n",
        "# 2) اجرای پردازش\n",
        "# در نوت‌بوک‌هایی که event loop فعال دارند:\n",
        "try:\n",
        "    import nest_asyncio, sys\n",
        "    nest_asyncio.apply()\n",
        "    loop = asyncio.get_event_loop()\n",
        "    if loop.is_running():\n",
        "        # اگر لوپ در حال اجراست (Jupyter)، از create_task استفاده می‌کنیم\n",
        "        task = loop.create_task(process_csv(lex_path, IN_CSV, IN_COL, OUT_CSV, OUT_COL))\n",
        "        await task  # در Colab/Notebook، await در سلول مجازه\n",
        "    else:\n",
        "        loop.run_until_complete(process_csv(lex_path, IN_CSV, IN_COL, OUT_CSV, OUT_COL))\n",
        "except RuntimeError:\n",
        "    # محیط‌های معمولی (اسکریپت)\n",
        "    asyncio.run(process_csv(lex_path, IN_CSV, IN_COL, OUT_CSV, OUT_COL))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WqAe79CU029",
        "outputId": "1e758754-521c-458b-d5b6-416ccd3f532a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved to farsi_async_faspell_corrected_on_normalized.csv\n"
          ]
        }
      ]
    }
  ]
}